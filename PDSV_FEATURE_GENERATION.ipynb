{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import hdbscan\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stl import mesh as np_mesh  # Import numpy-stl\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import psutil\n",
    "import shutil\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "input_folder = r\"C:\\Users\\soura\\Desktop\\PDSV_codes\\stliitm\"  # Path to your STL files\n",
    "\n",
    "if os.path.exists(input_folder):\n",
    "    print(\"Directory exists\")\n",
    "else:\n",
    "    print(\"Directory does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path: C:\\Users\\soura\\Desktop\\PDSV_codes\\mtech_project_feature_folder\n",
      "feature folder: C:\\Users\\soura\\Desktop\\PDSV_codes\\mtech_project_feature_folder\\proj_features\n",
      "feature folder: C:\\Users\\soura\\Desktop\\PDSV_codes\\mtech_project_feature_folder\\normal_features\n",
      "feature folder: C:\\Users\\soura\\Desktop\\PDSV_codes\\mtech_project_feature_folder\\surface_features\n"
     ]
    }
   ],
   "source": [
    "base_path = r\"C:\\Users\\soura\\Desktop\\PDSV_codes\\mtech_project_feature_folder\"\n",
    "print(\"Base path:\", base_path)\n",
    "\n",
    "proj_features_folder = os.path.join(base_path, 'proj_features')   # Folder to save projection features\n",
    "os.makedirs(proj_features_folder, exist_ok=True)\n",
    "print(\"feature folder:\", proj_features_folder)\n",
    "\n",
    "\n",
    "normal_features_folder = os.path.join(base_path, 'normal_features')   # Folder to save normal features\n",
    "os.makedirs(normal_features_folder, exist_ok=True)\n",
    "print(\"feature folder:\", normal_features_folder)\n",
    "\n",
    "surface_features_folder = os.path.join(base_path, 'surface_features')   # Folder to save normal features\n",
    "os.makedirs(surface_features_folder, exist_ok=True)\n",
    "print(\"feature folder:\", surface_features_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and perform clustering.\n",
    "stl_files = [f for f in os.listdir(input_folder) if f.endswith('.stl')]  # listing all stl files from the input file.\n",
    "print(stl_files)\n",
    "print(len(stl_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proj_DBhelper:\n",
    "    def __init__(self, data_base):\n",
    "        try:\n",
    "            self.conn = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"\", database=data_base)\n",
    "            self.mycursor = self.conn.cursor()\n",
    "        except:\n",
    "            print(\"some has occured\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Database is connected\")\n",
    "\n",
    "    def create_table(self, table_name):\n",
    "        try:\n",
    "            create_table_query = f\"\"\"\n",
    "                                    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                                        id INT(11) AUTO_INCREMENT PRIMARY KEY,\n",
    "                                        file_name VARCHAR(255) NULL,\n",
    "                                        proj_feature_vector VARCHAR(255) NULL,\n",
    "                                        cluster_label INT(11) NULL\n",
    "                                    );\"\"\"\n",
    "            self.mycursor.execute(create_table_query)\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(\"Table has not been created\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Table is ready.\")\n",
    "\n",
    "    def register(self, stl_file, cluster_label = -1):\n",
    "        try:\n",
    "            insert_query = \"\"\"INSERT INTO `stl_5000` (`file_name`, `cluster_label`) VALUES (%s, %s);\"\"\"\n",
    "            self.mycursor.execute(insert_query, (stl_file, cluster_label))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"{stl_file} could not entered in the database\")\n",
    "        else:\n",
    "            print(f\"{stl_file} is entered in the database\")\n",
    "        \n",
    "        \n",
    "    def update_cluster_label(self, stl_file, cluster_label):\n",
    "        try:\n",
    "            update_query = \"\"\"UPDATE `stl_5000` SET `cluster_label` = %s WHERE `stl_5000`.`file_name` = %s;\"\"\"\n",
    "            self.mycursor.execute(update_query, (cluster_label, stl_file))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"could not able to update for the {stl_file}\")\n",
    "        else:\n",
    "            print(f\"updatation of label is sucessfull for the {stl_file}\")\n",
    "        \n",
    "        \n",
    "    def update_feature_vector(self, stl_file, proj_feature):\n",
    "        try:\n",
    "            update_query = \"\"\"UPDATE `stl_5000` SET `proj_feature_vector` = %s WHERE `stl_5000`.`file_name` = %s;\"\"\"\n",
    "            self.mycursor.execute(update_query, (proj_feature, stl_file))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"The vectors could not enter in the database\")\n",
    "        else:\n",
    "            print(f\"The vectors are entered in the database\")\n",
    "        \n",
    "    def search_feature_vector(self, stl_file):\n",
    "        try:\n",
    "            self.mycursor.execute(\"\"\"SELECT proj_feature_vector FROM stl_5000\n",
    "                                WHERE file_name LIKE '{}'\"\"\".format(stl_file))\n",
    "            data = self.mycursor.fetchone()\n",
    "            return data[0]\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def search_feature_vector_through_id(self, id_number):\n",
    "        try:\n",
    "            self.mycursor.execute(\"\"\"SELECT file_name, proj_feature_vector FROM stl_5000\n",
    "                                WHERE id LIKE '{}'\"\"\".format(id_number))\n",
    "            data = self.mycursor.fetchone()\n",
    "            return data[0], data[1]\n",
    "        except:\n",
    "            return None, None\n",
    "        \n",
    "    def search_cluster_label_files(self, cluster_label):\n",
    "        try:\n",
    "            search_query = \"\"\"SELECT `file_name` FROM `stl_5000` WHERE `cluster_label` LIKE %s\"\"\"\n",
    "            self.mycursor.execute(search_query, (cluster_label,))\n",
    "            data = self.mycursor.fetchall()\n",
    "            return data, True\n",
    "        except:\n",
    "            return None, False\n",
    "    \n",
    "    def search_corresponding_label(self, stl_file):\n",
    "        try:\n",
    "            search_query = \"\"\"SELECT `cluster_label` FROM `stl_5000` WHERE `file_name` LIKE %s\"\"\"\n",
    "            self.mycursor.execute(search_query, (stl_file,))\n",
    "            data = self.mycursor.fetchone()\n",
    "            return data[0]\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def search_max_cluster_label(self):\n",
    "        try:\n",
    "            query = \"\"\"SELECT MAX(cluster_label) FROM stl_5000\"\"\"\n",
    "            self.mycursor.execute(query)\n",
    "            max_value = self.mycursor.fetchone()\n",
    "            return max_value[0]\n",
    "        except:\n",
    "            return -1\n",
    "        \n",
    "    def search_total_files(self):\n",
    "        try:\n",
    "            query = \"\"\"SELECT MAX(id) FROM stl_5000\"\"\"\n",
    "            self.mycursor.execute(query)\n",
    "            max_value = self.mycursor.fetchone()\n",
    "            return max_value[0]\n",
    "        except:\n",
    "            return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proj_Feature_Data_Base:\n",
    "    def __init__(self, data_base):                               \n",
    "        self.db = Proj_DBhelper(data_base)   #connect to the database\n",
    "\n",
    "    def table_creation(self, table_name):\n",
    "        self.db.create_table(table_name)    #create table\n",
    "        \n",
    "    def send_files_to_db(self, stl_files):\n",
    "        for file in stl_files:\n",
    "            self.db.register(file)\n",
    "                \n",
    "    def send_labels_to_db(self, stl_file, cluster_label):\n",
    "        self.db.update_cluster_label(stl_file, cluster_label)\n",
    "\n",
    "    def send_feature_vector_to_db(self, stl_file, proj_vector):\n",
    "        self.db.update_feature_vector(stl_file, proj_vector)\n",
    "        \n",
    "    def find_feature_vector(self, stl_file):\n",
    "        vector_file_name = self.db.search_feature_vector(stl_file)\n",
    "        if vector_file_name:\n",
    "            return vector_file_name, True\n",
    "        else:\n",
    "            return None, False\n",
    "        \n",
    "    def find_feature_vector_through_id(self, id_number):\n",
    "        file_name, vector_file_name = self.db.search_feature_vector_through_id(id_number)\n",
    "        if vector_file_name:\n",
    "            return file_name, vector_file_name, True\n",
    "        else:\n",
    "            return file_name, None, False\n",
    "        \n",
    "    def find_files(self, cluster_label):\n",
    "        data, flag = self.db.search_cluster_label_files(cluster_label)\n",
    "        if(flag):\n",
    "            if(len(data) > 0):\n",
    "                return data\n",
    "        return None\n",
    "\n",
    "    def find_label(self, stl_file):\n",
    "        data = self.db.search_corresponding_label(stl_file)\n",
    "        if data:\n",
    "            return data\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def maximum_cluster_label(self):\n",
    "        number = self.db.search_max_cluster_label()\n",
    "        return number\n",
    "    \n",
    "    def count_files(self):\n",
    "        number = self.db.search_total_files()\n",
    "        return number\n",
    "\n",
    "    def data_distribution(self):\n",
    "        length = self.maximum_cluster_label()\n",
    "        dictionary = {}\n",
    "        for i in range(length+1):\n",
    "            num_files = self.db.search_cluster_label_files(i)\n",
    "            dictionary[i] = len(num_files)\n",
    "\n",
    "        clusters = list(dictionary.keys())\n",
    "        values = list(dictionary.values())\n",
    "        \n",
    "        fig = plt.figure(figsize = (20, 10))\n",
    "\n",
    "        # creating the bar plot\n",
    "        plt.bar(clusters, values, color ='maroon', width = 0.8)\n",
    "\n",
    "        plt.xlabel(\"Cluster labels\")\n",
    "        plt.ylabel(\"No. of files of corresponding labels\")\n",
    "        plt.title(\"clusters vs no. of files\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is connected\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "\n",
    "s1 = Proj_Feature_Data_Base(\"mtech_project_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table is ready.\n"
     ]
    }
   ],
   "source": [
    "# Create the table.\n",
    "\n",
    "s1.table_creation(\"stl_5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.send_files_to_db(stl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal_DBhelper:\n",
    "    def __init__(self, data_base):\n",
    "        try:\n",
    "            self.conn = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"\", database=data_base)\n",
    "            self.mycursor = self.conn.cursor()\n",
    "        except:\n",
    "            print(\"some has occured\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Database is connected\")\n",
    "\n",
    "    def create_table(self, table_name):\n",
    "        try:\n",
    "            create_table_query = f\"\"\"\n",
    "                                    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                                        id INT(11) AUTO_INCREMENT PRIMARY KEY,\n",
    "                                        file_name VARCHAR(255) NULL,\n",
    "                                        normal_feature_vector VARCHAR(255) NULL,\n",
    "                                        surface_feature_vector VARCHAR(255) NULL\n",
    "                                    );\"\"\"\n",
    "            self.mycursor.execute(create_table_query)\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(\"Table could not be created\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Table is ready.\")\n",
    "\n",
    "    def register(self, stl_file):\n",
    "        try:\n",
    "            insert_query = \"\"\"INSERT INTO `stl_5000_normal` (`file_name`) VALUES (%s);\"\"\"\n",
    "            self.mycursor.execute(insert_query, (stl_file,))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"{stl_file} could not entered in the database\")\n",
    "        else:\n",
    "            print(f\"{stl_file} has entered in the database\")\n",
    "        \n",
    "        \n",
    "    def update_feature_vector(self, stl_file, normal_feature, surface_feature):\n",
    "        try:\n",
    "            update_query = \"\"\"UPDATE `stl_5000_normal` SET `normal_feature_vector` = %s, `surface_feature_vector` = %s WHERE `stl_5000_normal`.`file_name` = %s;\"\"\"\n",
    "            self.mycursor.execute(update_query, (normal_feature, surface_feature, stl_file))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"The vectors could not enter in the database\")\n",
    "        else:\n",
    "            print(f\"The vectors have been entered in the database\")\n",
    "        \n",
    "    def search_feature_vector(self, stl_file):\n",
    "        try:\n",
    "            self.mycursor.execute(\"\"\"SELECT normal_feature_vector, surface_feature_vector FROM stl_5000_normal\n",
    "                                WHERE file_name LIKE '{}'\"\"\".format(stl_file))\n",
    "            data = self.mycursor.fetchone()\n",
    "            return data[0], data[1]\n",
    "        except:\n",
    "            return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal_Surface_Database:\n",
    "    def __init__(self, data_base):                               \n",
    "        self.db = Normal_DBhelper(data_base)   #connect to the database\n",
    "\n",
    "    def table_creation(self, table_name):\n",
    "        self.db.create_table(table_name)    #create table\n",
    "        \n",
    "    def send_files_to_db(self, stl_files):\n",
    "        for file in stl_files:\n",
    "            self.db.register(file)\n",
    "\n",
    "    def send_feature_vector_to_db(self, stl_file, normal_vector, surface_vector):\n",
    "        self.db.update_feature_vector(stl_file, normal_vector, surface_vector)\n",
    "        \n",
    "    def find_feature_vector(self, stl_file):\n",
    "        normal_vector_file_path, surface_vector_file_path = self.db.search_feature_vector(stl_file)\n",
    "        if normal_vector_file_path:\n",
    "            return normal_vector_file_path, surface_vector_file_path,True\n",
    "        else:\n",
    "            return None, None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is connected\n"
     ]
    }
   ],
   "source": [
    "n1 = Normal_Surface_Database(\"mtech_project_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table is ready.\n"
     ]
    }
   ],
   "source": [
    "n1.table_creation(\"stl_5000_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1.send_files_to_db(stl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained SqueezeNet and modify it\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.squeezenet = models.squeezenet1_1(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.squeezenet.children())[:-1])\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)  # Apply Global Average Pooling\n",
    "        return x.view(x.size(0), -1) \n",
    "        #return self.features(x).view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soura\\anaconda3\\envs\\pdsv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\soura\\anaconda3\\envs\\pdsv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Move the model to CPU\n",
    "model = FeatureExtractor().eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class calculate_projection:\n",
    "    def __init__(self, data_base, cnn_model, input_folder, features_folder):\n",
    "        self.data_base = data_base\n",
    "        self.cnn_model = cnn_model\n",
    "        self.input_folder = input_folder\n",
    "        self.features_folder = features_folder\n",
    "        self.preprocess = transforms.Compose([\n",
    "                            transforms.ToPILImage(),\n",
    "                            transforms.Resize((224, 224)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ])\n",
    "\n",
    "\n",
    "    def generate_projections(self, stl_file_path):\n",
    "        try:\n",
    "            # Load STL file with numpy-stl\n",
    "            your_mesh = np_mesh.Mesh.from_file(stl_file_path)\n",
    "            print(f\"Loaded {stl_file_path}\")  # Debug print\n",
    "\n",
    "            # Extract vertices and faces\n",
    "            vertices = your_mesh.vectors.reshape(-1, 3)\n",
    "            faces = np.arange(len(vertices)).reshape(-1, 3)\n",
    "\n",
    "            ranges = vertices.max(axis=0)-vertices.min(axis=0)\n",
    "            middle = (vertices.max(axis=0)+vertices.min(axis=0))/2\n",
    "            largest_diff, largest_diff_ind = np.max(ranges), np.argmax(ranges)\n",
    "            eps = 0.05\n",
    "\n",
    "            X_min, X_max = 0, 0\n",
    "            Y_min, Y_max = 0, 0 \n",
    "            Z_min, Z_max = 0, 0\n",
    "            if(largest_diff_ind == 0):\n",
    "                X_min, X_max = middle[0]-largest_diff/2-10*eps, middle[0]+largest_diff/2+10*eps\n",
    "                Y_min, Y_max = middle[1]-largest_diff/2-eps, middle[1]+largest_diff/2+eps\n",
    "                Z_min, Z_max = middle[2]-largest_diff/2-eps, middle[2]+largest_diff/2+eps\n",
    "\n",
    "            if(largest_diff_ind == 1):\n",
    "                X_min, X_max = middle[0]-largest_diff/2-eps, middle[0]+largest_diff/2+eps\n",
    "                Y_min, Y_max = middle[1]-largest_diff/2-10*eps, middle[1]+largest_diff/2+10*eps\n",
    "                Z_min, Z_max = middle[2]-largest_diff/2-eps, middle[2]+largest_diff/2+eps\n",
    "                \n",
    "            if(largest_diff_ind == 2):\n",
    "                X_min, X_max = middle[0]-largest_diff/2-eps, middle[0]+largest_diff/2+eps\n",
    "                Y_min, Y_max = middle[1]-largest_diff/2-eps, middle[1]+largest_diff/2+eps\n",
    "                Z_min, Z_max = middle[2]-largest_diff/2-10*eps, middle[2]+largest_diff/2+10*eps\n",
    "\n",
    "            # Create a figure for plotting\n",
    "            fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "            # Isometric view\n",
    "            iso_views = []\n",
    "            for ele, azi in [(30, 45), (30, 225), (-30, 135), (-30, 315)]:\n",
    "                ax = fig.add_subplot(111, projection='3d')\n",
    "                ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], triangles=faces, cmap='gray', edgecolor='none')\n",
    "                ax.view_init(elev=ele, azim=azi)\n",
    "                ax.set_xlim(X_min, X_max)\n",
    "                ax.set_ylim(Y_min, Y_max)\n",
    "                ax.set_zlim(Z_min, Z_max)\n",
    "                plt.axis('off')\n",
    "                fig.tight_layout(pad=0)\n",
    "                fig.canvas.draw()\n",
    "                iso_view = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "                iso_views.append(iso_view)\n",
    "                plt.clf()\n",
    "\n",
    "            # Orthographic views\n",
    "            ortho_views = []\n",
    "            for ele, azi in [(90, 0), (-90, 0), (0, 0), (0, 90), (0, 180), (0, 270)]:\n",
    "                ax = fig.add_subplot(111, projection='3d')\n",
    "                ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], triangles=faces, cmap='gray', edgecolor='none')\n",
    "                ax.view_init(elev=ele, azim=azi)\n",
    "                ax.set_xlim(X_min, X_max)\n",
    "                ax.set_ylim(Y_min, Y_max)\n",
    "                ax.set_zlim(Z_min, Z_max)\n",
    "                plt.axis('off')\n",
    "                fig.tight_layout(pad=0)\n",
    "                fig.canvas.draw()\n",
    "                ortho_view = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "                ortho_views.append(ortho_view)\n",
    "                plt.clf()\n",
    "\n",
    "            plt.close(fig)\n",
    "            print(f\"Generated projections for {stl_file_path}\")  # Debug print\n",
    "            return iso_views, ortho_views\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {stl_file_path}: {e}\")\n",
    "            return None, None\n",
    "        \n",
    "    def create_batch(self, proj):\n",
    "        processed_images = []\n",
    "        for img in proj:\n",
    "            img_tensor = self.preprocess(img)  # Apply transformations\n",
    "            processed_images.append(img_tensor)\n",
    "\n",
    "        # Stack processed images into a single tensor\n",
    "        batch_tensor = torch.stack(processed_images)\n",
    "        return batch_tensor\n",
    "    \n",
    "    def process_files(self, stl_files):\n",
    "        for i, stl_file in enumerate(stl_files, 1):  # Start enumeration at 1\n",
    "            file_path = os.path.join(self.input_folder, stl_file)\n",
    "\n",
    "            # Generate projections\n",
    "            iso_views, ortho_views = self.generate_projections(file_path)\n",
    "\n",
    "            if iso_views is None or ortho_views is None:\n",
    "                continue # Skip if there was an error in generating projections\n",
    "\n",
    "            # Extract features from projections\n",
    "            projections = iso_views + ortho_views\n",
    "            batch_tensor = self.create_batch(projections)\n",
    "            proj_feature = 0\n",
    "            with torch.no_grad():\n",
    "                proj_feature = self.cnn_model(batch_tensor.to(device)).cpu().numpy().flatten()\n",
    "\n",
    "            # Save the features with the same name as the STL file\n",
    "            feature_file_name = os.path.join(self.features_folder, f\"{os.path.splitext(stl_file)[0]}_features.npy\")\n",
    "            np.save(feature_file_name, proj_feature)\n",
    "            self.data_base.send_feature_vector_to_db(stl_file, feature_file_name)\n",
    "            # Print progress\n",
    "            print(f\"Processed and saved features for {i}/{len(stl_files)}: {stl_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_projection_object = calculate_projection(s1, model, input_folder, proj_features_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_projection_object.process_files(stl_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\soura\\\\Desktop\\\\PDSV_codes\\\\stl_5000_feature_folder\\\\proj_features\\\\1040433_p2_prt_features.npy'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_representation_path, flag = s1.find_feature_vector(stl_files[5])\n",
    "vector_representation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/proj_features/1040433_p2_prt_features.npy'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_representation_path = vector_representation_path.replace(\"\\\\\", \"/\")\n",
    "vector_representation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/proj_features/1040433_p2_prt_features.npy\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(vector_representation_path):\n",
    "    print(f\"The directory is : {vector_representation_path}\")\n",
    "else:\n",
    "    print(f\"The directory does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5120,)\n"
     ]
    }
   ],
   "source": [
    "vector_representative = np.load(vector_representation_path)\n",
    "vector = np.array(vector_representative)\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040433_p2_prt.stl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\soura\\\\Desktop\\\\PDSV_codes\\\\stl_5000_feature_folder\\\\proj_features\\\\1040433_p2_prt_features.npy'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name, vector_representation_path, flag = s1.find_feature_vector_through_id(6)\n",
    "print(file_name)\n",
    "vector_representation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_projection_object.process_files(stl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For normal feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal_Surface_feature_generation:\n",
    "    def __init__(self, Normal_Surface_data_base, input_folder, normal_features_folder, surface_features_folder):\n",
    "        self.Normal_Surface_data_base = Normal_Surface_data_base\n",
    "        self.input_folder = input_folder\n",
    "        self.normal_features_folder = normal_features_folder\n",
    "        self.surface_features_folder = surface_features_folder\n",
    "        \n",
    "    def calculate_direction_vector(self, angle_x, angle_y):\n",
    "        angle_x = np.radians(angle_x)\n",
    "        angle_y = np.radians(angle_y)\n",
    "        \n",
    "        x = np.cos(angle_x) * np.cos(angle_y)\n",
    "        y = np.cos(angle_x) * np.sin(angle_y)\n",
    "        z = np.sin(angle_x)\n",
    "        \n",
    "        return np.array([x, y, z]) / np.linalg.norm([x, y, z])\n",
    "    \n",
    "    def ray_triangle_intersect(self, origin, direction, vertices, epsilon=1e-6):\n",
    "        # Triangle vertices\n",
    "        v0, v1, v2 = vertices\n",
    "        \n",
    "        # Edge vectors of the triangle\n",
    "        edge1 = v1 - v0\n",
    "        edge2 = v2 - v0\n",
    "        \n",
    "        # Calculate the determinant\n",
    "        h = np.cross(direction, edge2)\n",
    "        a = np.dot(edge1, h)\n",
    "        \n",
    "        # If the determinant is near zero, the ray is parallel to the triangle\n",
    "        if abs(a) < epsilon:\n",
    "            return False\n",
    "\n",
    "        f = 1.0 / a\n",
    "        s = origin - v0\n",
    "        u = f * np.dot(s, h)\n",
    "        \n",
    "        # Check if u is within bounds\n",
    "        if u < 0.0 or u > 1.0:\n",
    "            return False\n",
    "\n",
    "        q = np.cross(s, edge1)\n",
    "        v = f * np.dot(direction, q)\n",
    "        \n",
    "        # Check if v is within bounds and u + v <= 1\n",
    "        if v < 0.0 or u + v > 1.0:\n",
    "            return False\n",
    "\n",
    "        # Calculate t to find the intersection point\n",
    "        t = f * np.dot(edge2, q)\n",
    "        \n",
    "        # Check if the intersection is valid (t > 0 indicates intersection)\n",
    "        if t > epsilon:\n",
    "            return True  # There is a valid intersection\n",
    "        \n",
    "        return False  # No valid intersection\n",
    "\n",
    "    \n",
    "    def find_intersecting_facet(self, mesh, direction_vector):\n",
    "        center = np.mean(mesh.points.reshape(-1, 3), axis=0)\n",
    "        for i, triangle in enumerate(mesh.vectors):\n",
    "            normal = mesh.normals[i]\n",
    "            vertices = triangle\n",
    "            if self.ray_triangle_intersect(center, direction_vector, vertices):\n",
    "                return normal, vertices\n",
    "        return None, None\n",
    "\n",
    "    def find_normal(self, stl_file_path):\n",
    "        # Load the STL file\n",
    "        try:\n",
    "            your_mesh = np_mesh.Mesh.from_file(stl_file_path)\n",
    "            lst = [(30, 45), (30, 225), (-30, 135), (-30, 315), (90, 0), (-90, 0), (0, 0), (0, 90), (0, 180), (0, 270)]\n",
    "            \n",
    "            vertices = your_mesh.vectors.reshape(-1, 3)\n",
    "            volume, cog, inertia = your_mesh.get_mass_properties()\n",
    "\n",
    "            ranges = vertices.max(axis=0)-vertices.min(axis=0)\n",
    "\n",
    "            # Surface Area\n",
    "            surface_area = 0.5 * np.linalg.norm(\n",
    "                np.cross(your_mesh.vectors[:, 1] - your_mesh.vectors[:, 0], your_mesh.vectors[:, 2] - your_mesh.vectors[:, 0]), axis=1).sum()\n",
    "\n",
    "            vector = np.array([ranges[2], ranges[0], ranges[1], surface_area, volume])\n",
    "\n",
    "            # Define the direction vector\n",
    "            concatenated_vector = np.array([0])\n",
    "            for ele in lst:\n",
    "                direction = self.calculate_direction_vector(ele[0],  ele[1])\n",
    "\n",
    "                # Find the intersecting facet and its normal\n",
    "                normal, vertices = self.find_intersecting_facet(your_mesh, direction)\n",
    "\n",
    "                if normal is None:\n",
    "                    normal = np.array([0, 0, 0])\n",
    "\n",
    "                concatenated_vector = np.concatenate([concatenated_vector, normal])\n",
    "            \n",
    "            return concatenated_vector, vector\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {stl_file_path}: {e}\")\n",
    "            return None, None\n",
    "        \n",
    "    def process_files(self, stl_files):\n",
    "        for i, stl_file in enumerate(stl_files, 1):  # Start enumeration at 1\n",
    "            file_path = os.path.join(self.input_folder, stl_file)\n",
    "\n",
    "            normal_vector, surface_vector = self.find_normal(file_path)\n",
    "            if normal_vector is None or surface_vector is None:\n",
    "                continue\n",
    "\n",
    "            # Save the normal features with the same name as the STL file\n",
    "            normal_feature_file = os.path.join(self.normal_features_folder, f\"{os.path.splitext(stl_file)[0]}_normal_features.npy\")\n",
    "            np.save(normal_feature_file, normal_vector)\n",
    "\n",
    "            # Save the normal features with the same name as the STL file\n",
    "            surface_feature_file = os.path.join(self.surface_features_folder, f\"{os.path.splitext(stl_file)[0]}_surface_features.npy\")\n",
    "            np.save(surface_feature_file, surface_vector)\n",
    "\n",
    "            #Save the features with the same name as the STL file\n",
    "            self.Normal_Surface_data_base.send_feature_vector_to_db(stl_file,\n",
    "                                                                     normal_feature_file,\n",
    "                                                                     surface_feature_file)\n",
    "            # Print progress\n",
    "            print(f\"Processed and saved features for {i}/{len(stl_files)}: {stl_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Surface_feature_generation_instance = Normal_Surface_feature_generation(n1,\n",
    "                                                                                input_folder,\n",
    "                                                                                normal_features_folder,\n",
    "                                                                                surface_features_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Surface_feature_generation_instance.process_files(stl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\soura\\\\Desktop\\\\PDSV_codes\\\\stl_5000_feature_folder\\\\normal_features\\\\1040433_p2_prt_normal_features.npy'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_path, surface_path,  flag = n1.find_feature_vector(stl_files[5])\n",
    "normal_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\soura\\\\Desktop\\\\PDSV_codes\\\\stl_5000_feature_folder\\\\surface_features\\\\1040433_p2_prt_surface_features.npy'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surface_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1040433_p2_prt_normal_features.npy'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_path = normal_path.replace(\"\\\\\", \"/\")\n",
    "normal_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1040433_p2_prt_surface_features.npy'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surface_path = surface_path.replace(\"\\\\\", \"/\")\n",
    "surface_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1040433_p2_prt_normal_features.npy\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(normal_path):\n",
    "    print(f\"The directory is : {normal_path}\")\n",
    "    normal_vactor = np.load(normal_path)\n",
    "    normal_vactor = np.array(normal_vactor)\n",
    "    print(normal_vactor.shape)\n",
    "else:\n",
    "    print(f\"The directory does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1040433_p2_prt_surface_features.npy\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(surface_path):\n",
    "    print(f\"The directory is : {surface_path}\")\n",
    "    surface_vactor = np.load(surface_path)\n",
    "    surface_vactor = np.array(surface_vactor)\n",
    "    print(surface_vactor.shape)\n",
    "else:\n",
    "    print(f\"The directory does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = s1.count_files()\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.find_feature_vector_through_id(4266)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdsv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
