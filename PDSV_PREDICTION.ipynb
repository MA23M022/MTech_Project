{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import ast\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import hdbscan\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stl import mesh as np_mesh  # Import numpy-stl\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import psutil\n",
    "import shutil\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path: C:\\Users\\soura\\Desktop\\PDSV_codes\\stl_5000_feature_folder\n",
      "feature folder: C:\\Users\\soura\\Desktop\\PDSV_codes\\stl_5000_feature_folder\\proj_features\n",
      "feature folder: C:\\Users\\soura\\Desktop\\PDSV_codes\\stl_5000_feature_folder\\normal_features\n",
      "feature folder: C:\\Users\\soura\\Desktop\\PDSV_codes\\stl_5000_feature_folder\\surface_features\n"
     ]
    }
   ],
   "source": [
    "base_path = r\"C:\\Users\\soura\\Desktop\\PDSV_codes\\stl_5000_feature_folder\"\n",
    "print(\"Base path:\", base_path)\n",
    "\n",
    "proj_features_folder = os.path.join(base_path, 'proj_features')   # Folder to save projection features\n",
    "os.makedirs(proj_features_folder, exist_ok=True)\n",
    "print(\"feature folder:\", proj_features_folder)\n",
    "\n",
    "normal_features_folder = os.path.join(base_path, 'normal_features')   # Folder to save normal features\n",
    "os.makedirs(normal_features_folder, exist_ok=True)\n",
    "print(\"feature folder:\", normal_features_folder)\n",
    "\n",
    "surface_features_folder = os.path.join(base_path, 'surface_features')   # Folder to save normal features\n",
    "os.makedirs(surface_features_folder, exist_ok=True)\n",
    "print(\"feature folder:\", surface_features_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proj_DBhelper:\n",
    "    def __init__(self, data_base):\n",
    "        try:\n",
    "            self.conn = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"\", database=data_base)\n",
    "            self.mycursor = self.conn.cursor()\n",
    "        except:\n",
    "            print(\"some has occured\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Database is connected\")\n",
    "\n",
    "    def create_table(self, table_name):\n",
    "        try:\n",
    "            create_table_query = f\"\"\"\n",
    "                                    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                                        id INT(11) AUTO_INCREMENT PRIMARY KEY,\n",
    "                                        file_name VARCHAR(255) NULL,\n",
    "                                        proj_feature_vector VARCHAR(255) NULL,\n",
    "                                        cluster_label INT(11) NULL\n",
    "                                    );\"\"\"\n",
    "            self.mycursor.execute(create_table_query)\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(\"Table has not been created\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Table is ready.\")\n",
    "\n",
    "    def register(self, stl_file, cluster_label = -1):\n",
    "        try:\n",
    "            insert_query = \"\"\"INSERT INTO `stl_5000` (`file_name`, `cluster_label`) VALUES (%s, %s);\"\"\"\n",
    "            self.mycursor.execute(insert_query, (stl_file, cluster_label))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"{stl_file} could not entered in the projection database\")\n",
    "        else:\n",
    "            print(f\"{stl_file} has been entered in the projection database\")\n",
    "        \n",
    "        \n",
    "    def update_cluster_label(self, stl_file, cluster_label):\n",
    "        try:\n",
    "            update_query = \"\"\"UPDATE `stl_5000` SET `cluster_label` = %s WHERE `stl_5000`.`file_name` = %s;\"\"\"\n",
    "            self.mycursor.execute(update_query, (cluster_label, stl_file))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"could not able to update for the {stl_file}\")\n",
    "        else:\n",
    "            print(f\"updatation of label is sucessfull for the {stl_file}\")\n",
    "        \n",
    "        \n",
    "    def update_feature_vector(self, stl_file, proj_feature):\n",
    "        try:\n",
    "            update_query = \"\"\"UPDATE `stl_5000` SET `proj_feature_vector` = %s WHERE `stl_5000`.`file_name` = %s;\"\"\"\n",
    "            self.mycursor.execute(update_query, (proj_feature, stl_file))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"The vectors could not enter in the projection database\")\n",
    "        else:\n",
    "            print(f\"The vector has been entered in the projection database\")\n",
    "        \n",
    "    def search_feature_vector(self, stl_file):\n",
    "        try:\n",
    "            self.mycursor.execute(\"\"\"SELECT proj_feature_vector FROM stl_5000\n",
    "                                WHERE file_name LIKE '{}'\"\"\".format(stl_file))\n",
    "            data = self.mycursor.fetchone()\n",
    "            return data[0]\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def search_feature_vector_through_id(self, id_number):\n",
    "        try:\n",
    "            self.mycursor.execute(\"\"\"SELECT file_name, proj_feature_vector FROM stl_5000\n",
    "                                WHERE id LIKE '{}'\"\"\".format(id_number))\n",
    "            data = self.mycursor.fetchone()\n",
    "            return data[0], data[1]\n",
    "        except:\n",
    "            return None, None\n",
    "        \n",
    "    def search_cluster_label_files(self, cluster_label):\n",
    "        try:\n",
    "            search_query = \"\"\"SELECT `file_name` FROM `stl_5000` WHERE `cluster_label` LIKE %s\"\"\"\n",
    "            self.mycursor.execute(search_query, (cluster_label,))\n",
    "            data = self.mycursor.fetchall()\n",
    "            return data, True\n",
    "        except:\n",
    "            return None, False\n",
    "    \n",
    "    def search_corresponding_label(self, stl_file):\n",
    "        try:\n",
    "            search_query = \"\"\"SELECT `cluster_label` FROM `stl_5000` WHERE `file_name` LIKE %s\"\"\"\n",
    "            self.mycursor.execute(search_query, (stl_file,))\n",
    "            data = self.mycursor.fetchone()\n",
    "            return data[0]\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def search_max_cluster_label(self):\n",
    "        try:\n",
    "            query = \"\"\"SELECT MAX(cluster_label) FROM stl_5000\"\"\"\n",
    "            self.mycursor.execute(query)\n",
    "            max_value = self.mycursor.fetchone()\n",
    "            return max_value[0]\n",
    "        except:\n",
    "            return -1\n",
    "        \n",
    "    def search_total_files(self):\n",
    "        try:\n",
    "            query = \"\"\"SELECT MAX(id) FROM stl_5000\"\"\"\n",
    "            self.mycursor.execute(query)\n",
    "            max_value = self.mycursor.fetchone()\n",
    "            return max_value[0]\n",
    "        except:\n",
    "            return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proj_Feature_Data_Base:\n",
    "    def __init__(self, data_base):                               \n",
    "        self.db = Proj_DBhelper(data_base)   #connect to the database\n",
    "\n",
    "    def table_creation(self, table_name):\n",
    "        self.db.create_table(table_name)    #create table\n",
    "        \n",
    "    def send_files_to_db(self, stl_files):\n",
    "        for file in stl_files:\n",
    "            self.db.register(file)\n",
    "                \n",
    "    def send_labels_to_db(self, stl_file, cluster_label):\n",
    "        self.db.update_cluster_label(stl_file, cluster_label)\n",
    "\n",
    "    def send_feature_vector_to_db(self, stl_file, proj_vector):\n",
    "        self.db.update_feature_vector(stl_file, proj_vector)\n",
    "        \n",
    "    def find_feature_vector(self, stl_file):\n",
    "        vector_file_name = self.db.search_feature_vector(stl_file)\n",
    "        if vector_file_name:\n",
    "            return vector_file_name, True\n",
    "        else:\n",
    "            return None, False\n",
    "        \n",
    "    def find_feature_vector_through_id(self, id_number):\n",
    "        file_name, vector_file_name = self.db.search_feature_vector_through_id(id_number)\n",
    "        if vector_file_name:\n",
    "            return file_name, vector_file_name, True\n",
    "        else:\n",
    "            return file_name, None, False\n",
    "        \n",
    "    def find_files(self, cluster_label):\n",
    "        data, flag = self.db.search_cluster_label_files(cluster_label)\n",
    "        if(flag):\n",
    "            if(len(data) > 0):\n",
    "                return data\n",
    "        return None\n",
    "\n",
    "    def find_label(self, stl_file):\n",
    "        data = self.db.search_corresponding_label(stl_file)\n",
    "        if data:\n",
    "            return data\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def maximum_cluster_label(self,):\n",
    "        number = self.db.search_max_cluster_label()\n",
    "        return number\n",
    "    \n",
    "    def count_files(self,):\n",
    "        number = self.db.search_total_files()\n",
    "        return number\n",
    "\n",
    "    def data_distribution(self,):\n",
    "        length = self.maximum_cluster_label()\n",
    "        dictionary = {}\n",
    "        for i in range(length+1):\n",
    "            num_files = self.db.search_cluster_label_files(i)\n",
    "            dictionary[i] = len(num_files)\n",
    "\n",
    "        clusters = list(dictionary.keys())\n",
    "        values = list(dictionary.values())\n",
    "        \n",
    "        fig = plt.figure(figsize = (20, 10))\n",
    "\n",
    "        # creating the bar plot\n",
    "        plt.bar(clusters, values, color ='maroon', width = 0.8)\n",
    "\n",
    "        plt.xlabel(\"Cluster labels\")\n",
    "        plt.ylabel(\"No. of files of corresponding labels\")\n",
    "        plt.title(\"clusters vs no. of files\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is connected\n"
     ]
    }
   ],
   "source": [
    "s1 = Proj_Feature_Data_Base(\"aws_database_dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal_DBhelper:\n",
    "    def __init__(self, data_base):\n",
    "        try:\n",
    "            self.conn = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"\", database=data_base)\n",
    "            self.mycursor = self.conn.cursor()\n",
    "        except:\n",
    "            print(\"some has occured\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Database is connected\")\n",
    "\n",
    "    def create_table(self, table_name):\n",
    "        try:\n",
    "            create_table_query = f\"\"\"\n",
    "                                    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                                        id INT(11) AUTO_INCREMENT PRIMARY KEY,\n",
    "                                        file_name VARCHAR(255) NULL,\n",
    "                                        normal_feature_vector VARCHAR(255) NULL,\n",
    "                                        surface_feature_vector VARCHAR(255) NULL\n",
    "                                    );\"\"\"\n",
    "            self.mycursor.execute(create_table_query)\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(\"Table could not be created\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Table is ready.\")\n",
    "\n",
    "    def register(self, stl_file):\n",
    "        try:\n",
    "            insert_query = \"\"\"INSERT INTO `stl_5000_normal` (`file_name`) VALUES (%s);\"\"\"\n",
    "            self.mycursor.execute(insert_query, (stl_file,))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"{stl_file} could not entered in the normal database\")\n",
    "        else:\n",
    "            print(f\"{stl_file} has been entered in the normal database\")\n",
    "        \n",
    "        \n",
    "    def update_feature_vector(self, stl_file, normal_feature, surface_feature):\n",
    "        try:\n",
    "            update_query = \"\"\"UPDATE `stl_5000_normal` SET `normal_feature_vector` = %s, `surface_feature_vector` = %s WHERE `stl_5000_normal`.`file_name` = %s;\"\"\"\n",
    "            self.mycursor.execute(update_query, (normal_feature, surface_feature, stl_file))\n",
    "            self.conn.commit()\n",
    "        except:\n",
    "            print(f\"The vectors could not enter in the normal database\")\n",
    "        else:\n",
    "            print(f\"The vectors have been entered in the normal database\")\n",
    "        \n",
    "    def search_feature_vector(self, stl_file):\n",
    "        try:\n",
    "            self.mycursor.execute(\"\"\"SELECT normal_feature_vector, surface_feature_vector FROM stl_5000_normal\n",
    "                                WHERE file_name LIKE '{}'\"\"\".format(stl_file))\n",
    "            data = self.mycursor.fetchone()\n",
    "            return data[0], data[1]\n",
    "        except:\n",
    "            return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal_Surface_Database:\n",
    "    def __init__(self, data_base):                               \n",
    "        self.db = Normal_DBhelper(data_base)   #connect to the database\n",
    "\n",
    "    def table_creation(self, table_name):\n",
    "        self.db.create_table(table_name)    #create table\n",
    "        \n",
    "    def send_files_to_db(self, stl_files):\n",
    "        for file in stl_files:\n",
    "            self.db.register(file)\n",
    "\n",
    "    def send_feature_vector_to_db(self, stl_file, normal_vector, surface_vector):\n",
    "        self.db.update_feature_vector(stl_file, normal_vector, surface_vector)\n",
    "        \n",
    "    def find_feature_vector(self, stl_file):\n",
    "        normal_vector_file_path, surface_vector_file_path = self.db.search_feature_vector(stl_file)\n",
    "        if normal_vector_file_path:\n",
    "            return normal_vector_file_path, surface_vector_file_path,True\n",
    "        else:\n",
    "            return None, None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is connected\n"
     ]
    }
   ],
   "source": [
    "n1 = Normal_Surface_Database(\"aws_database_dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained SqueezeNet and modify it\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.squeezenet = models.squeezenet1_1(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.squeezenet.children())[:-1])\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)  # Apply Global Average Pooling\n",
    "        return x.view(x.size(0), -1) \n",
    "        #return self.features(x).view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soura\\anaconda3\\envs\\pdsv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\soura\\anaconda3\\envs\\pdsv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Move the model to CPU\n",
    "model = FeatureExtractor().eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, proj_feature_data_base, normal_surface_data_base,\n",
    "                  proj_features_folder, normal_features_folder, surface_features_folder,\n",
    "                  representative_folder, test_folder, cnn_model,  threshold = 0.97):\n",
    "        \n",
    "        self.proj_feature_data_base = proj_feature_data_base\n",
    "        self.normal_surface_data_base = normal_surface_data_base\n",
    "        self.proj_features_folder = proj_features_folder\n",
    "        self.normal_features_folder = normal_features_folder\n",
    "        self.surface_features_folder = surface_features_folder\n",
    "        self.representative_folder = representative_folder\n",
    "        self.test_folder = test_folder\n",
    "        self.cnn_model = cnn_model\n",
    "        self.threshold = threshold\n",
    "        self.test_file_name = None\n",
    "        self.test_file_path = None\n",
    "        self.test_feature = None\n",
    "        self.sorted_similar_cluster_index = None\n",
    "        self.test_cluster_label = -1\n",
    "        self.test_similarity_score  = -1\n",
    "        self.preprocess = transforms.Compose([\n",
    "                            transforms.ToPILImage(),\n",
    "                            transforms.Resize((224, 224)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ])\n",
    "\n",
    "    def generate_projections(self, stl_file_path):\n",
    "        try:\n",
    "            # Load STL file with numpy-stl\n",
    "            your_mesh = np_mesh.Mesh.from_file(stl_file_path)\n",
    "            print(f\"Loaded {stl_file_path}\")  # Debug print\n",
    "\n",
    "            # Extract vertices and faces\n",
    "            vertices = your_mesh.vectors.reshape(-1, 3)\n",
    "            faces = np.arange(len(vertices)).reshape(-1, 3)\n",
    "\n",
    "            ranges = vertices.max(axis=0)-vertices.min(axis=0)\n",
    "            middle = (vertices.max(axis=0)+vertices.min(axis=0))/2\n",
    "            largest_diff, largest_diff_ind = np.max(ranges), np.argmax(ranges)\n",
    "            eps = 0.05\n",
    "\n",
    "            X_min, X_max = 0, 0\n",
    "            Y_min, Y_max = 0, 0 \n",
    "            Z_min, Z_max = 0, 0\n",
    "            if(largest_diff_ind == 0):\n",
    "                X_min, X_max = middle[0]-largest_diff/2-10*eps, middle[0]+largest_diff/2+10*eps\n",
    "                Y_min, Y_max = middle[1]-largest_diff/2-eps, middle[1]+largest_diff/2+eps\n",
    "                Z_min, Z_max = middle[2]-largest_diff/2-eps, middle[2]+largest_diff/2+eps\n",
    "\n",
    "            if(largest_diff_ind == 1):\n",
    "                X_min, X_max = middle[0]-largest_diff/2-eps, middle[0]+largest_diff/2+eps\n",
    "                Y_min, Y_max = middle[1]-largest_diff/2-10*eps, middle[1]+largest_diff/2+10*eps\n",
    "                Z_min, Z_max = middle[2]-largest_diff/2-eps, middle[2]+largest_diff/2+eps\n",
    "                \n",
    "            if(largest_diff_ind == 2):\n",
    "                X_min, X_max = middle[0]-largest_diff/2-eps, middle[0]+largest_diff/2+eps\n",
    "                Y_min, Y_max = middle[1]-largest_diff/2-eps, middle[1]+largest_diff/2+eps\n",
    "                Z_min, Z_max = middle[2]-largest_diff/2-10*eps, middle[2]+largest_diff/2+10*eps\n",
    "\n",
    "            # Create a figure for plotting\n",
    "            fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "            # Isometric view\n",
    "            iso_views = []\n",
    "            for ele, azi in [(30, 45), (30, 225), (-30, 135), (-30, 315)]:\n",
    "                ax = fig.add_subplot(111, projection='3d')\n",
    "                ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], triangles=faces, cmap='gray', edgecolor='none')\n",
    "                ax.view_init(elev=ele, azim=azi)\n",
    "                ax.set_xlim(X_min, X_max)\n",
    "                ax.set_ylim(Y_min, Y_max)\n",
    "                ax.set_zlim(Z_min, Z_max)\n",
    "                plt.axis('off')\n",
    "                fig.tight_layout(pad=0)\n",
    "                fig.canvas.draw()\n",
    "                iso_view = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "                iso_views.append(iso_view)\n",
    "                plt.clf()\n",
    "\n",
    "            # Orthographic views\n",
    "            ortho_views = []\n",
    "            for ele, azi in [(90, 0), (-90, 0), (0, 0), (0, 90), (0, 180), (0, 270)]:\n",
    "                ax = fig.add_subplot(111, projection='3d')\n",
    "                ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], triangles=faces, cmap='gray', edgecolor='none')\n",
    "                ax.view_init(elev=ele, azim=azi)\n",
    "                ax.set_xlim(X_min, X_max)\n",
    "                ax.set_ylim(Y_min, Y_max)\n",
    "                ax.set_zlim(Z_min, Z_max)\n",
    "                plt.axis('off')\n",
    "                fig.tight_layout(pad=0)\n",
    "                fig.canvas.draw()\n",
    "                ortho_view = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "                ortho_views.append(ortho_view)\n",
    "                plt.clf()\n",
    "\n",
    "            plt.close(fig)\n",
    "            print(f\"Generated projections for {stl_file_path}\")  # Debug print\n",
    "            return iso_views, ortho_views\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {stl_file_path}: {e}\")\n",
    "            return None, None\n",
    "        \n",
    "    def create_batch(self, proj):\n",
    "        processed_images = []\n",
    "        for img in proj:\n",
    "            img_tensor = self.preprocess(img)  # Apply transformations\n",
    "            processed_images.append(img_tensor)\n",
    "\n",
    "        # Stack processed images into a single tensor\n",
    "        batch_tensor = torch.stack(processed_images)\n",
    "        return batch_tensor\n",
    "    \n",
    "\n",
    "    def generate_test_feature(self):\n",
    "        # Generate projections\n",
    "        iso_views, ortho_views = self.generate_projections(self.test_file_path)\n",
    "\n",
    "        if iso_views is None or ortho_views is None:\n",
    "            return None, False                                # Skip if there was an error in generating projections\n",
    "\n",
    "        # Extract features from projections\n",
    "        projections = iso_views + ortho_views\n",
    "        batch_tensor = self.create_batch(projections)\n",
    "        feature = None\n",
    "        with torch.no_grad():\n",
    "            feature = self.cnn_model(batch_tensor.to(device)).cpu().numpy().flatten()\n",
    "\n",
    "        return feature, True\n",
    "    \n",
    "    def search_similar_cluster(self):\n",
    "        self.test_feature, flag = self.generate_test_feature()\n",
    "        if flag:\n",
    "            main_vector = self.test_feature\n",
    "            all_representative_path = os.path.join(self.representative_folder, f'all_clusters_representative.npy')   # Here we need s3 bucket.\n",
    "            sim_cluster_index = {}\n",
    "            if os.path.exists(all_representative_path):\n",
    "                all_representative = np.load(all_representative_path)\n",
    "                vectors = np.array(all_representative)\n",
    "\n",
    "                # Normalize the vectors\n",
    "                main_vector_norm = main_vector / np.linalg.norm(main_vector)\n",
    "                vectors_norm = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "                # Compute cosine similarity\n",
    "                similarity_scores = np.dot(vectors_norm, main_vector_norm)\n",
    "\n",
    "                # Find indices where values are greater than the threshold\n",
    "                indices = np.where(similarity_scores > self.threshold)[0]\n",
    "                for i in range(len(indices)):\n",
    "                    sim_cluster_index[indices[i]] = similarity_scores[indices[i]]\n",
    "                self.sorted_similar_cluster_index = dict(sorted(sim_cluster_index.items(), key = lambda x : x[1], reverse=True))\n",
    "            else:\n",
    "                print(f\"Some error has been occured\")\n",
    "        else:\n",
    "            print(\"Could not bale to generate projection feature of the query stl file\")\n",
    "\n",
    "    def calculate_direction_vector(self, angle_x, angle_y):\n",
    "        angle_x = np.radians(angle_x)\n",
    "        angle_y = np.radians(angle_y)\n",
    "        \n",
    "        x = np.cos(angle_x) * np.cos(angle_y)\n",
    "        y = np.cos(angle_x) * np.sin(angle_y)\n",
    "        z = np.sin(angle_x)\n",
    "        \n",
    "        return np.array([x, y, z]) / np.linalg.norm([x, y, z])\n",
    "    \n",
    "    def ray_triangle_intersect(self, origin, direction, vertices, epsilon=1e-6):\n",
    "        # Triangle vertices\n",
    "        v0, v1, v2 = vertices\n",
    "        \n",
    "        # Edge vectors of the triangle\n",
    "        edge1 = v1 - v0\n",
    "        edge2 = v2 - v0\n",
    "        \n",
    "        # Calculate the determinant\n",
    "        h = np.cross(direction, edge2)\n",
    "        a = np.dot(edge1, h)\n",
    "        \n",
    "        # If the determinant is near zero, the ray is parallel to the triangle\n",
    "        if abs(a) < epsilon:\n",
    "            return False\n",
    "\n",
    "        f = 1.0 / a\n",
    "        s = origin - v0\n",
    "        u = f * np.dot(s, h)\n",
    "        \n",
    "        # Check if u is within bounds\n",
    "        if u < 0.0 or u > 1.0:\n",
    "            return False\n",
    "\n",
    "        q = np.cross(s, edge1)\n",
    "        v = f * np.dot(direction, q)\n",
    "        \n",
    "        # Check if v is within bounds and u + v <= 1\n",
    "        if v < 0.0 or u + v > 1.0:\n",
    "            return False\n",
    "\n",
    "        # Calculate t to find the intersection point\n",
    "        t = f * np.dot(edge2, q)\n",
    "        \n",
    "        # Check if the intersection is valid (t > 0 indicates intersection)\n",
    "        if t > epsilon:\n",
    "            return True  # There is a valid intersection\n",
    "        \n",
    "        return False  # No valid intersection\n",
    "\n",
    "    \n",
    "    def find_intersecting_facet(self, mesh, direction_vector):\n",
    "        center = np.mean(mesh.points.reshape(-1, 3), axis=0)\n",
    "        for i, triangle in enumerate(mesh.vectors):\n",
    "            normal = mesh.normals[i]\n",
    "            vertices = triangle\n",
    "            if self.ray_triangle_intersect(center, direction_vector, vertices):\n",
    "                return normal, vertices\n",
    "        return None, None\n",
    "\n",
    "    def find_normal(self):\n",
    "        try:\n",
    "            # Load the STL file\n",
    "            your_mesh = np_mesh.Mesh.from_file(self.test_file_path)\n",
    "            lst = [(30, 45), (30, 225), (-30, 135), (-30, 315), (90, 0), (-90, 0), (0, 0), (0, 90), (0, 180), (0, 270)]\n",
    "            \n",
    "            vertices = your_mesh.vectors.reshape(-1, 3)\n",
    "            volume, cog, inertia = your_mesh.get_mass_properties()\n",
    "\n",
    "            ranges = vertices.max(axis=0)-vertices.min(axis=0)\n",
    "\n",
    "            # Surface Area\n",
    "            surface_area = 0.5 * np.linalg.norm(\n",
    "                np.cross(your_mesh.vectors[:, 1] - your_mesh.vectors[:, 0], your_mesh.vectors[:, 2] - your_mesh.vectors[:, 0]), axis=1).sum()\n",
    "\n",
    "            vector = np.array([ranges[2], ranges[0], ranges[1], surface_area, volume])\n",
    "\n",
    "            # Define the direction vector\n",
    "            concatenated_vector = np.array([0])\n",
    "            for ele in lst:\n",
    "                direction = self.calculate_direction_vector(ele[0],  ele[1])\n",
    "\n",
    "                # Find the intersecting facet and its normal\n",
    "                normal, vertices = self.find_intersecting_facet(your_mesh, direction)\n",
    "\n",
    "                if normal is None:\n",
    "                    normal = np.array([0, 0, 0])\n",
    "\n",
    "                concatenated_vector = np.concatenate([concatenated_vector, normal])\n",
    "            return concatenated_vector, vector\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {self.test_file_path}: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "\n",
    "    def evaluate_similarity(self, cluster_label, test_normal_feature, test_surface_feature):\n",
    "        cluster_files_from_db = self.proj_feature_data_base.find_files(cluster_label)\n",
    "        cluster_files = []\n",
    "        if cluster_files_from_db != None:\n",
    "            for element in cluster_files_from_db:\n",
    "                cluster_files.append(element[0])\n",
    "\n",
    "        similar_stl_files = {}\n",
    "        for file_name in cluster_files:\n",
    "            n_fea_path, s_fea_path, flag = self.normal_surface_data_base.find_feature_vector(file_name)\n",
    "            if flag:\n",
    "                n_fea_path = n_fea_path.replace(\"\\\\\", \"/\")\n",
    "                s_fea_path = s_fea_path.replace(\"\\\\\", \"/\")\n",
    "                if os.path.exists(n_fea_path) and os.path.exists(s_fea_path):\n",
    "                    print(f\"The directory of naormal is : {n_fea_path}\")\n",
    "                    print(f\"The directory of surface is : {s_fea_path}\")\n",
    "                    n_feature = np.load(n_fea_path)\n",
    "                    s_feature = np.load(s_fea_path)\n",
    "                    s1 = cosine_similarity(n_feature.reshape(1, -1), test_normal_feature.reshape(1, -1))\n",
    "                    s2 = cosine_similarity(s_feature.reshape(1, -1), test_surface_feature.reshape(1, -1))\n",
    "                    similar_stl_files[file_name] = s1[0][0]*s2[0][0]\n",
    "                else:\n",
    "                    print(f\"The Normal or Surface directory does not exist\")\n",
    "            else:\n",
    "                print(f\"There is no information in the database for the file : {file_name}\")\n",
    "            \n",
    "        sorted_similar_stl_files = list(sorted(similar_stl_files.items(), key = lambda x : x[1], reverse=True))\n",
    "        if sorted_similar_stl_files:\n",
    "            if int(sorted_similar_stl_files[0][1]) > self.test_similarity_score:\n",
    "                self.test_similarity_score = int(sorted_similar_stl_files[0][1])\n",
    "                self.test_cluster_label = cluster_label\n",
    "\n",
    "        print(f\"For cluster label {cluster_label}:\")\n",
    "        print(sorted_similar_stl_files)\n",
    "\n",
    "    def similar_stl_files_inside_similar_clusters(self, test_file):\n",
    "        self.test_file_name = test_file             # Here we need s3 bucket.\n",
    "        self.test_file_path = os.path.join(self.test_folder, self.test_file_name)           # Here we need s3 bucket.\n",
    "        self.search_similar_cluster()\n",
    "        test_normal_feature, test_surface_feature = self.find_normal()\n",
    "        if (self.sorted_similar_cluster_index is not None) and (test_normal_feature is not None):\n",
    "            cluster_labels = list(self.sorted_similar_cluster_index)\n",
    "            for cluster_label in cluster_labels:\n",
    "                self.evaluate_similarity(int(cluster_label), test_normal_feature, test_surface_feature)\n",
    "\n",
    "\n",
    "            test_stl_files = [self.test_file_name]\n",
    "            self.proj_feature_data_base.send_files_to_db(test_stl_files)\n",
    "            self.normal_surface_data_base.send_files_to_db(test_stl_files)\n",
    "\n",
    "            # Save the features with the same name as the STL file\n",
    "            proj_feature_file_path = os.path.join(self.proj_features_folder,\n",
    "                                                   f\"{os.path.splitext(self.test_file_name)[0]}_features.npy\")\n",
    "            np.save(proj_feature_file_path, self.test_feature)\n",
    "            self.proj_feature_data_base.send_feature_vector_to_db(self.test_file_name, proj_feature_file_path)\n",
    "            # Print progress\n",
    "            print(f\"Processed and saved features for {self.test_file_name}\")\n",
    "\n",
    "\n",
    "            # Save the normal features with the same name as the STL file\n",
    "            normal_feature_file = os.path.join(self.normal_features_folder,\n",
    "                                                f\"{os.path.splitext(self.test_file_name)[0]}_normal_features.npy\")\n",
    "            np.save(normal_feature_file, test_normal_feature)\n",
    "\n",
    "            # Save the normal features with the same name as the STL file\n",
    "            surface_feature_file = os.path.join(self.surface_features_folder,\n",
    "                                                 f\"{os.path.splitext(self.test_file_name)[0]}_surface_features.npy\")\n",
    "            np.save(surface_feature_file, test_surface_feature)\n",
    "\n",
    "            #Save the features with the same name as the STL file\n",
    "            self.normal_surface_data_base.send_feature_vector_to_db(self.test_file_name,\n",
    "                                                                     normal_feature_file,\n",
    "                                                                     surface_feature_file)\n",
    "            # Print progress\n",
    "            print(f\"Processed and saved Normal and Surface features for {self.test_file_name}\")\n",
    "\n",
    "\n",
    "            if self.test_similarity_score >= self.threshold:\n",
    "                print(f\"The test files's cluster label is {self.test_cluster_label}\")\n",
    "                self.proj_feature_data_base.send_labels_to_db(self.test_file_name, self.test_cluster_label)\n",
    "            else:\n",
    "                curr_max_cluster_label = self.proj_feature_data_base.maximum_cluster_label()\n",
    "                print(f\"The test files's cluster label is {curr_max_cluster_label+1}\")\n",
    "                self.proj_feature_data_base.send_labels_to_db(self.test_file_name, curr_max_cluster_label+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory is : .\\stl_5000_representative\n"
     ]
    }
   ],
   "source": [
    "cluster_representative_folder = r\".\\stl_5000_representative\"\n",
    "if os.path.exists(cluster_representative_folder):\n",
    "    print(f\"The directory is : {cluster_representative_folder}\")\n",
    "else:\n",
    "    print(f\"The directory does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.find_label(\"1159809_210-12551_prt.stl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1159737_210-12550_prt.stl',), ('1159809_210-12551_prt.stl',)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.find_files(467)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory is : .\\stl_test\n"
     ]
    }
   ],
   "source": [
    "stl_test_folder = r\".\\stl_test\"\n",
    "if os.path.exists(stl_test_folder):\n",
    "    print(f\"The directory is : {stl_test_folder}\")\n",
    "else:\n",
    "    print(f\"The directory does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1168972_23-18495_prt.stl', '123561_313-568d_flat1_prt.stl', '175077_144-0659fr2_prt.stl', '175237_121-0875_prt.stl', '223492_test_part_1_prt.stl', 'project_test_1.stl', 'test_1.stl', 'test_2.stl', 'test_3.stl', 'test_4.stl']\n"
     ]
    }
   ],
   "source": [
    "test_files = [f for f in os.listdir(stl_test_folder) if f.endswith('.stl')]\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_test_1.stl'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particular_test_file = test_files[5]\n",
    "particular_test_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['project_test_1.stl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaadd = [particular_test_file]\n",
    "print(type(aaadd))\n",
    "aaadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_instance1 = Evaluation(s1, n1, proj_features_folder, \n",
    "                                  normal_features_folder, surface_features_folder,\n",
    "                                  cluster_representative_folder, stl_test_folder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .\\stl_test\\project_test_1.stl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_26220\\708380557.py:76: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  iso_view = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_26220\\708380557.py:92: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  ortho_view = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (3,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated projections for .\\stl_test\\project_test_1.stl\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159737_210-12550_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159737_210-12550_prt_surface_features.npy\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159809_210-12551_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159809_210-12551_prt_surface_features.npy\n",
      "For cluster label 467:\n",
      "[('1159809_210-12551_prt.stl', np.float64(1.0)), ('1159737_210-12550_prt.stl', np.float64(0.9996837228077463))]\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159566_210-12549_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159566_210-12549_prt_surface_features.npy\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159598_210-12543_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159598_210-12543_prt_surface_features.npy\n",
      "For cluster label 466:\n",
      "[('1159566_210-12549_prt.stl', np.float64(0.9995901257521567)), ('1159598_210-12543_prt.stl', np.float64(0.9995901257521567))]\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159676_210-12556_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159676_210-12556_prt_surface_features.npy\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159691_210-12552_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159691_210-12552_prt_surface_features.npy\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159761_210-12554_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159761_210-12554_prt_surface_features.npy\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159766_210-12553_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159766_210-12553_prt_surface_features.npy\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159801_210-12555_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159801_210-12555_prt_surface_features.npy\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159812_210-12557_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159812_210-12557_prt_surface_features.npy\n",
      "For cluster label 468:\n",
      "[('1159761_210-12554_prt.stl', np.float64(0.9501125199806845)), ('1159766_210-12553_prt.stl', np.float64(0.9494305917016294)), ('1159691_210-12552_prt.stl', np.float64(0.94927602323239)), ('1159801_210-12555_prt.stl', np.float64(0.9491727749700177)), ('1159676_210-12556_prt.stl', np.float64(0.9068271291137491)), ('1159812_210-12557_prt.stl', np.float64(0.9068066190088997))]\n",
      "The directory of naormal is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/normal_features/1159694_210-12548_prt_normal_features.npy\n",
      "The directory of surface is : C:/Users/soura/Desktop/PDSV_codes/stl_5000_feature_folder/surface_features/1159694_210-12548_prt_surface_features.npy\n",
      "For cluster label 1642:\n",
      "[('1159694_210-12548_prt.stl', np.float64(0.9997214268468081))]\n",
      "project_test_1.stl has been entered in the projection database\n",
      "project_test_1.stl has been entered in the normal database\n",
      "The vector has been entered in the projection database\n",
      "Processed and saved features for project_test_1.stl\n",
      "The vectors have been entered in the normal database\n",
      "Processed and saved Normal and Surface features for project_test_1.stl\n",
      "The test files's cluster label is 467\n",
      "updatation of label is sucessfull for the project_test_1.stl\n"
     ]
    }
   ],
   "source": [
    "Evaluation_instance1.similar_stl_files_inside_similar_clusters(particular_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('125636_311-892h_asm.stl',),\n",
       " ('125640_336-005h_asm.stl',),\n",
       " ('125642_311-700h_asm.stl',)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.find_files(783)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4278"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.count_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2813"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.maximum_cluster_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    return 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "a, b = func()\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdsv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
